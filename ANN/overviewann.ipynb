{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some random data\n",
    "X = np.random.rand(100, 3)  # 100 samples, 3 features each\n",
    "y = np.random.randint(0, 2, size=(100,))  # Binary target (0 or 1)\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Create a DataLoader for batching\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleANN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # Input to hidden\n",
    "        self.relu = nn.ReLU()                        # Activation\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)  # Hidden to output\n",
    "        self.sigmoid = nn.Sigmoid()                  # Output activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 3\n",
    "hidden_size = 5\n",
    "output_size = 1\n",
    "\n",
    "model = SimpleANN(input_size, hidden_size, output_size)\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.7181\n",
      "Epoch 2/50, Loss: 0.6898\n",
      "Epoch 3/50, Loss: 0.6957\n",
      "Epoch 4/50, Loss: 0.6988\n",
      "Epoch 5/50, Loss: 0.6865\n",
      "Epoch 6/50, Loss: 0.7145\n",
      "Epoch 7/50, Loss: 0.7006\n",
      "Epoch 8/50, Loss: 0.7013\n",
      "Epoch 9/50, Loss: 0.6806\n",
      "Epoch 10/50, Loss: 0.6823\n",
      "Epoch 11/50, Loss: 0.6708\n",
      "Epoch 12/50, Loss: 0.6968\n",
      "Epoch 13/50, Loss: 0.6835\n",
      "Epoch 14/50, Loss: 0.6639\n",
      "Epoch 15/50, Loss: 0.7311\n",
      "Epoch 16/50, Loss: 0.6681\n",
      "Epoch 17/50, Loss: 0.7203\n",
      "Epoch 18/50, Loss: 0.7028\n",
      "Epoch 19/50, Loss: 0.6725\n",
      "Epoch 20/50, Loss: 0.6964\n",
      "Epoch 21/50, Loss: 0.7043\n",
      "Epoch 22/50, Loss: 0.6613\n",
      "Epoch 23/50, Loss: 0.6676\n",
      "Epoch 24/50, Loss: 0.7083\n",
      "Epoch 25/50, Loss: 0.6582\n",
      "Epoch 26/50, Loss: 0.6793\n",
      "Epoch 27/50, Loss: 0.7214\n",
      "Epoch 28/50, Loss: 0.7017\n",
      "Epoch 29/50, Loss: 0.6741\n",
      "Epoch 30/50, Loss: 0.7210\n",
      "Epoch 31/50, Loss: 0.6922\n",
      "Epoch 32/50, Loss: 0.6892\n",
      "Epoch 33/50, Loss: 0.7311\n",
      "Epoch 34/50, Loss: 0.7997\n",
      "Epoch 35/50, Loss: 0.7044\n",
      "Epoch 36/50, Loss: 0.6819\n",
      "Epoch 37/50, Loss: 0.6966\n",
      "Epoch 38/50, Loss: 0.6681\n",
      "Epoch 39/50, Loss: 0.5831\n",
      "Epoch 40/50, Loss: 0.6990\n",
      "Epoch 41/50, Loss: 0.6566\n",
      "Epoch 42/50, Loss: 0.7129\n",
      "Epoch 43/50, Loss: 0.6090\n",
      "Epoch 44/50, Loss: 0.6239\n",
      "Epoch 45/50, Loss: 0.6413\n",
      "Epoch 46/50, Loss: 0.7588\n",
      "Epoch 47/50, Loss: 0.6812\n",
      "Epoch 48/50, Loss: 0.7280\n",
      "Epoch 49/50, Loss: 0.6350\n",
      "Epoch 50/50, Loss: 0.6661\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs.squeeze(), batch_y)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0.5698\n"
     ]
    }
   ],
   "source": [
    "# Test with a random sample\n",
    "test_sample = torch.tensor([[0.5, 0.2, 0.8]], dtype=torch.float32)\n",
    "prediction = model(test_sample)\n",
    "print(f\"Prediction: {prediction.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
